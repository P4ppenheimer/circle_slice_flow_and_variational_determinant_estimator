{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "import pprint\n",
    "import os\n",
    "import time\n",
    "\n",
    "# weights and biases for tracking of metrics\n",
    "import wandb \n",
    "\n",
    "# make the plots inline again\n",
    "%matplotlib inline\n",
    "from code import *\n",
    "\n",
    "# sometimes have to activate this to plot plots in notebook\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -0.0000,  0.0000],\n",
       "         [ 0.1966,  0.3300,  0.3017],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.3598, -0.0651, -0.4966],\n",
       "         [ 0.0000, -0.0000,  0.0000],\n",
       "         [ 0.3961,  0.3875,  0.1300],\n",
       "         [ 0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0648, -0.0135,  0.0542],\n",
       "         [-0.0000, -0.0000, -0.0000],\n",
       "         [-0.0767, -0.1602,  0.1372]],\n",
       "\n",
       "        [[ 0.0000, -0.0000,  0.0000],\n",
       "         [ 0.2599,  0.2730,  0.2178],\n",
       "         [-0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2914, -0.1302, -0.3019],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.3910,  0.3877,  0.0059],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0422,  0.0499,  0.2727],\n",
       "         [-0.0000, -0.0000, -0.0000],\n",
       "         [-0.0886,  0.0488,  0.1303]]], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_bins = 3\n",
    "num_bins_deriv = num_bins + 1\n",
    "\n",
    "num_dim = 10\n",
    "\n",
    "num_hidden = 12\n",
    "\n",
    "num_dim_conditioner = None\n",
    "\n",
    "batch = 2\n",
    "\n",
    "params_predictor = MLP_simple_coupling(num_inputs=num_dim, \n",
    "                               num_hidden=num_hidden, \n",
    "                               num_outputs_widhts_heights=num_bins * num_dim,\n",
    "                               num_outputs_derivatives=num_bins_deriv * num_dim,\n",
    "                               mask_alternate_flag = False,\n",
    "                               num_dim_conditioner=num_dim_conditioner)\n",
    "\n",
    "params_predictor.to(device)\n",
    "\n",
    "x = torch.rand(batch, num_dim).to(device)\n",
    "x_conditioner = None\n",
    "\n",
    "width, height, deriv = params_predictor(x=x, x_conditioner=x_conditioner)\n",
    "\n",
    "# (B, D*K)\n",
    "\n",
    " # (B, D, K) \n",
    " # (B, D, K)\n",
    "width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 2\n",
    "num_bins_deriv = num_bins + 1\n",
    "\n",
    "num_dim = 3\n",
    "\n",
    "num_hidden = 100\n",
    "\n",
    "num_dim_conditioner = None\n",
    "\n",
    "batch = 1\n",
    "\n",
    "params_predictor = MLP_masked(num_inputs=num_dim, \n",
    "                               num_hidden=num_hidden, \n",
    "                               num_outputs_widhts_heights=num_bins * num_dim,\n",
    "                               num_outputs_derivatives=num_bins_deriv * num_dim,\n",
    "                               mask_type = 'autoregressive',\n",
    "                               num_dim_conditioner=num_dim_conditioner)\n",
    "params_predictor.to(device)\n",
    "\n",
    "x = torch.rand(batch, num_dim).to(device)\n",
    "x_conditioner = None\n",
    "\n",
    "width, height, deriv = params_predictor(x=x, x_conditioner=x_conditioner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invertibility check coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### ISF\n",
    "\n",
    "NUM_BINS = 7\n",
    "NUM_DIM_DATA = 256\n",
    "NUM_CENTERS = 6\n",
    "batch = 10\n",
    "\n",
    "mask_type='autoregressive'\n",
    "mask_type='coupling'\n",
    "\n",
    "\n",
    "ISF = Interval_Spline_Flow(num_bins=NUM_BINS,\n",
    "                          num_dim=NUM_DIM_DATA ,\n",
    "                          num_dim_conditioner=None,\n",
    "                          num_hidden=HIDDEN_DIM_SPLINE_MLP,\n",
    "                          rezero_flag=False,\n",
    "                          mask_alternate_flag=False,\n",
    "                          mask_type=mask_type)\n",
    "\n",
    "ISF.to(device)\n",
    "\n",
    "heights = torch.rand(batch, NUM_DIM_DATA).to(device)*2-1\n",
    "\n",
    "z_heights, ldj = ISF(x = heights, \n",
    "                     x_conditioner = None,\n",
    "                     inverse = False)\n",
    "\n",
    "inverse, ldj_inv = ISF(x=z_heights,x_conditioner=None,inverse=True)\n",
    "\n",
    "print(torch.isclose(inverse,heights,atol=1e-5).all())\n",
    "print(torch.isclose(ldj+ldj_inv,torch.tensor(0.),atol=1e-4).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### CSF\n",
    "DIM_COND = 5\n",
    "CSF = Circular_Spline_Flow(num_bins=NUM_BINS,\n",
    "                           num_dim_conditioner=DIM_COND,\n",
    "                           rezero_flag=False,\n",
    "                           num_hidden=HIDDEN_DIM_SPLINE_MLP)\n",
    "\n",
    "CSF.to(device)\n",
    "\n",
    "thetas = torch.rand(batch, 1).to(device)*2*np.pi\n",
    "x_cond = torch.randn(batch,DIM_COND).to(device)\n",
    "r = torch.ones(batch,1).to(device)\n",
    "\n",
    "out, ldj = CSF(thetas,r=r, x_conditioner=x_cond)\n",
    "\n",
    "inverse, ldj_inv = CSF(out,r=r, x_conditioner=x_cond, inverse=True)\n",
    "\n",
    "print(torch.isclose(inverse,thetas,atol=1e-5).all())\n",
    "print(torch.isclose(ldj+ldj_inv,torch.tensor(0.),atol=1e-4).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### Moebius\n",
    "NUM_CENTERS = 1\n",
    "\n",
    "MOEB = Moebius_Flow(num_centers=NUM_CENTERS,\n",
    "                  learnable_convex_weights=False, \n",
    "                  num_dim_conditioner=DIM_COND,\n",
    "                  rezero_flag=False,\n",
    "                  num_hidden=HIDDEN_DIM_MOEBIUS_MLP)\n",
    "\n",
    "MOEB.to(device)\n",
    "\n",
    "thetas = torch.rand(batch, 1).to(device)*2*np.pi\n",
    "x_cond = torch.randn(batch,DIM_COND).to(device)\n",
    "r = torch.ones(batch,1).to(device)\n",
    "\n",
    "out, ldj = MOEB(thetas,r=r, x_conditioner=x_cond)\n",
    "\n",
    "inverse, ldj_inv = MOEB(out,r=r, x_conditioner=x_cond, inverse=True)\n",
    "\n",
    "print(torch.isclose(inverse,thetas,atol=1e-5).all())\n",
    "print(torch.isclose(ldj+ldj_inv,torch.tensor(0.),atol=1e-4).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### COUPLING CYL FLOW\n",
    "\n",
    "# NUM_FLOWS_CYL = 1\n",
    "# NUM_BINS = 7\n",
    "# NUM_DIM_DATA = 128\n",
    "# NUM_CENTERS = 1\n",
    "# batch = int(1e2)\n",
    "\n",
    "# mask_type='coupling'\n",
    "\n",
    "\n",
    "# cyl_moeb = Cylindrical_Flow(num_flows=NUM_FLOWS_CYL,\n",
    "#                              num_bins=NUM_BINS, \n",
    "#                              flow_type='spline',\n",
    "#                              num_dim_data=NUM_DIM_DATA, \n",
    "#                              mask_type=mask_type,\n",
    "#                              num_centers=NUM_CENTERS)\n",
    "\n",
    "\n",
    "# x_conditioner = None\n",
    "\n",
    "# x = torch.randn(batch, NUM_DIM_DATA)\n",
    "# x = x / torch.norm(x, dim = 1, keepdim = True)\n",
    "\n",
    "# x = x.to(device)\n",
    "# cyl_moeb.to(device)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     x_out, sldj, _ = cyl_moeb(x, x_conditioner)\n",
    "\n",
    "# print('sldj.mean()',sldj.mean())\n",
    "# print('sldj.exp().mean()',sldj.exp().mean())\n",
    "\n",
    "\n",
    "# inverse, sldj_inv, _ = cyl_moeb(x_out,x_conditioner,inverse=True)\n",
    "\n",
    "# print('inv ldj')\n",
    "# print(torch.isclose(sldj_inv + sldj,torch.tensor(0.),atol=1e-3).all())\n",
    "# print()\n",
    "# print('inverse input')\n",
    "# print(torch.isclose(inverse, x, atol=1e-3).all())\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### TRANSFORMATIONS\n",
    "NUM_DIM_DATA = 256\n",
    "batch = 10\n",
    "\n",
    "x_sphere = torch.randn(batch, NUM_DIM_DATA).to(device)\n",
    "x_sphere = x_sphere / torch.norm(x_sphere, dim = 1, keepdim = True)\n",
    "\n",
    "out, ldj = T_s_to_c(x_sphere)\n",
    "\n",
    "inv, ldj_inv = T_c_to_s(out)\n",
    "\n",
    "print(torch.isclose(ldj_inv + ldj,torch.tensor(0.),atol=1e-3).all())\n",
    "print(torch.isclose(inv, x_sphere, atol=1e-3).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ldjs close\n",
      "tensor(True, device='cuda:0')\n",
      "\n",
      "input output close\n",
      "tensor(True, device='cuda:0')\n",
      "absolute deviation\n",
      "tensor(5.47e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "### INVERTIBILITY on whole flow\n",
    "\n",
    "\n",
    "torch.set_printoptions(profile='short')\n",
    "\n",
    "NUM_FLOWS_CYL = 1\n",
    "NUM_BINS = 7\n",
    "NUM_DIM_DATA = 10\n",
    "NUM_CENTERS = 1\n",
    "BATCH = int(1e2)\n",
    "\n",
    "# mask_type='autoregressive'\n",
    "mask_type='coupling'\n",
    "mask_type='autoregressive'\n",
    "\n",
    "\n",
    "\n",
    "COU_CYL_MOEB = Cylindrical_Flow(num_flows=NUM_FLOWS_CYL,\n",
    "                             num_bins=NUM_BINS, \n",
    "                             flow_type='moebius',\n",
    "                             num_dim_data=NUM_DIM_DATA, \n",
    "                             mask_type=mask_type,\n",
    "                             num_centers=NUM_CENTERS)\n",
    "\n",
    "x_sphere = torch.randn(BATCH, NUM_DIM_DATA).to(device)\n",
    "x_sphere = x_sphere / torch.norm(x_sphere, dim = 1, keepdim = True)\n",
    "\n",
    "COU_CYL_MOEB.to(device)\n",
    "\n",
    "out, ldj, _ = COU_CYL_MOEB(x_sphere, x_conditioner=None, inverse=False)\n",
    "\n",
    "inv, ldj_inv, _ = COU_CYL_MOEB(out, x_conditioner=None, inverse=True)\n",
    "\n",
    "print('ldjs close')\n",
    "print(torch.isclose(ldj + ldj_inv,torch.tensor(0.),atol=1e-3).all())\n",
    "print()\n",
    "print('input output close')\n",
    "print(torch.isclose(x_sphere, inv, torch.tensor(0.), atol=1e-3).all())\n",
    "\n",
    "print('absolute deviation')\n",
    "print(torch.mean(torch.abs(x_sphere-inv)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum to one check cylindrical, AR and COU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coupling\n",
      " i 0 dj 0.999668538570404\n",
      " i 1 dj 1.0001345872879028\n",
      " i 2 dj 0.9998093247413635\n",
      " i 3 dj 0.9995474219322205\n",
      " i 4 dj 1.000051736831665\n",
      " i 5 dj 1.000525712966919\n",
      " i 6 dj 1.0003795623779297\n",
      " i 7 dj 0.9998641610145569\n",
      " i 8 dj 0.9995902180671692\n",
      " i 9 dj 1.0002408027648926\n",
      " i 10 dj 0.9999060034751892\n",
      " i 11 dj 1.0001438856124878\n",
      " i 12 dj 0.9997997879981995\n",
      " i 13 dj 1.0002793073654175\n",
      " i 14 dj 0.9994960427284241\n",
      " i 15 dj 0.999741792678833\n",
      " i 16 dj 1.0000211000442505\n",
      " i 17 dj 0.9997199177742004\n",
      " i 18 dj 1.0003302097320557\n",
      " i 19 dj 1.0005011558532715\n",
      "autoregressive\n",
      " i 0 dj 1.000296950340271\n",
      " i 1 dj 1.0002079010009766\n",
      " i 2 dj 1.000687837600708\n",
      " i 3 dj 1.0002484321594238\n",
      " i 4 dj 0.9997518062591553\n",
      " i 5 dj 0.9997839331626892\n",
      " i 6 dj 0.9995958805084229\n",
      " i 7 dj 1.0003015995025635\n",
      " i 8 dj 1.0003743171691895\n",
      " i 9 dj 0.999902606010437\n",
      " i 10 dj 1.00031578540802\n",
      " i 11 dj 1.0004234313964844\n",
      " i 12 dj 0.9995601177215576\n",
      " i 13 dj 0.9997401237487793\n",
      " i 14 dj 1.0000686645507812\n",
      " i 15 dj 1.0005773305892944\n",
      " i 16 dj 0.9993418455123901\n",
      " i 17 dj 0.9999356269836426\n",
      " i 18 dj 0.9998614192008972\n",
      " i 19 dj 0.9996492862701416\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "NUM_FLOWS_CYL = 8\n",
    "NUM_BINS = 16\n",
    "NUM_DIM_DATA = 128\n",
    "NUM_CENTERS = 1\n",
    "BATCH = int(1e4)\n",
    "\n",
    "mask_type='coupling'\n",
    "mask_type='autoregressive'\n",
    "\n",
    "\n",
    "for mask_type in ('coupling','autoregressive'):\n",
    "    print(mask_type)\n",
    "    ldj_list = []\n",
    "\n",
    "    for i in range(20):\n",
    "        COU_CYL_MOEB = Cylindrical_Flow(num_flows=NUM_FLOWS_CYL,\n",
    "                                     num_bins=NUM_BINS, \n",
    "                                     flow_type='spline',\n",
    "                                     num_dim_data=NUM_DIM_DATA, \n",
    "                                     mask_type=mask_type,\n",
    "                                     num_centers=NUM_CENTERS)\n",
    "\n",
    "        COU_CYL_MOEB.to(device)\n",
    "\n",
    "        ldj_total = torch.tensor([]).to(device)\n",
    "\n",
    "        x_sphere = torch.randn(BATCH, NUM_DIM_DATA).to(device)\n",
    "        x_sphere = x_sphere / torch.norm(x_sphere, dim = 1, keepdim = True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out, ldj, _ = COU_CYL_MOEB(x_sphere, x_conditioner=None, inverse=False)\n",
    "\n",
    "        ldj_total = torch.cat([ldj_total, ldj])  \n",
    "\n",
    "        dj = ldj_total.exp().mean()\n",
    "        print(f' i {i} dj {dj}')\n",
    "        ldj_list.append(dj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum to one check coupling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm out tensor(True, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.00, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_FLOWS_COU = 10\n",
    "NUM_BINS = 7\n",
    "NUM_DIM_DATA = 128\n",
    "NUM_CENTERS = 1\n",
    "BATCH = int(1e4)\n",
    "\n",
    "COU_MOEB = Coupling_Flow(num_flows = NUM_FLOWS_COU, \n",
    "                              num_dim_data= NUM_DIM_DATA,\n",
    "                              flow_type = 'moebius', \n",
    "                              num_centers = NUM_CENTERS,\n",
    "                              cap_householder_refl=True)\n",
    "\n",
    "COU_MOEB.to(device)\n",
    "\n",
    "\n",
    "x_sphere = torch.randn(BATCH, NUM_DIM_DATA).to(device)\n",
    "x_sphere = x_sphere / torch.norm(x_sphere, dim = 1, keepdim = True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out, ldj, _ = COU_MOEB(x_sphere, x_conditioner=None, inverse=False)\n",
    "\n",
    "print('norm out', torch.isclose(torch.norm(out,dim=1),torch.tensor(1.)).all())\n",
    "ldj.exp().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow_lab",
   "language": "python",
   "name": "flow_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
